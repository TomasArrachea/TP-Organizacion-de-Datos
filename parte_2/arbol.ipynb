{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f002d2",
   "metadata": {},
   "source": [
    "# Modelos usando el algoritmo de arboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040ca8e",
   "metadata": {},
   "source": [
    "### Importación de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd5e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import informe\n",
    "import preprocessing\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6db92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSPREADHSEET_DOWNLOAD_URL = (\n",
    "    \"https://docs.google.com/spreadsheets/d/{gid}/export?format=csv&id={gid}\".format\n",
    ")\n",
    "\n",
    "FIUFIP_2021_1_GID = '1-DWTP8uwVS-dZY402-dm0F9ICw_6PNqDGLmH0u8Eqa0'\n",
    "df = pd.read_csv(GSPREADHSEET_DOWNLOAD_URL(gid=FIUFIP_2021_1_GID))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687bc4bc",
   "metadata": {},
   "source": [
    "### Llamado a funciones de preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f49d0",
   "metadata": {},
   "source": [
    "#### Conversión de variables\n",
    "- Hay que convertir todos los features categóricos a númericos. Para variables categóricas se usarán Dummy Variables y para ordinales OrdinalEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e62895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.remove_irrelevant_features(df)\n",
    "df = preprocessing.missings_treatment(df)\n",
    "df = preprocessing.one_hot_encodding(df)\n",
    "X = df.drop('tiene_alto_valor_adquisitivo', axis='columns')\n",
    "\n",
    "# Se separa el dataset en entrenamiento y holdout\n",
    "y = df.tiene_alto_valor_adquisitivo\n",
    "X_train, X_holdout, y_train, y_holdout = preprocessing.dataset_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5cb1c",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804d458",
   "metadata": {},
   "source": [
    "#### Modelo 1\n",
    "- Se usan todos los features para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aecdd23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados modelo 1\n",
      "    Mejores hiperparámetros: {'min_samples_leaf': 15, 'max_depth': 8}\n",
      "    Métrica AUC ROC: 0.90\n",
      "    Otras metricas:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17303\n",
      "           1       0.80      0.55      0.65      5489\n",
      "\n",
      "    accuracy                           0.86     22792\n",
      "   macro avg       0.84      0.75      0.78     22792\n",
      "weighted avg       0.85      0.86      0.85     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo1 = tree.DecisionTreeClassifier(random_state=117)\n",
    "params = {'max_depth': np.arange(1, 9), 'min_samples_leaf': np.arange(1, 16)}\n",
    "\n",
    "metricas = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    modelo1, params, n_iter=60, scoring=metricas, n_jobs=-1, cv=5, return_train_score=True, refit = 'roc_auc'\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "informe.imprimir_metricas(rscv, X_train, y_train, nombre = \"modelo 1\")\n",
    "\n",
    "modelo1 = rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d7aeb",
   "metadata": {},
   "source": [
    "#### Modelo 2\n",
    "- se seleccionan los features mas relevantes haciendo embedding, el resto se descartan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e7fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c = X_train.copy()\n",
    "\n",
    "features_relevantes = preprocessing.embedded(X_train_c, y_train, min_importance=0.05).columns\n",
    "X_train_reducido = X_train[features_relevantes]\n",
    "X_holdout_reducido = X_holdout[features_relevantes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465a7381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados modelo 2\n",
      "    Mejores hiperparámetros: {'min_samples_leaf': 5, 'max_depth': 8}\n",
      "    Métrica AUC ROC: 0.90\n",
      "    Otras metricas:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17303\n",
      "           1       0.81      0.54      0.65      5489\n",
      "\n",
      "    accuracy                           0.86     22792\n",
      "   macro avg       0.84      0.75      0.78     22792\n",
      "weighted avg       0.85      0.86      0.85     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo2 = tree.DecisionTreeClassifier(random_state=117)\n",
    "params = {'max_depth': np.arange(2, 9), 'min_samples_leaf': np.arange(2, 16)}\n",
    "\n",
    "metricas = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    modelo2, params, n_iter=60, scoring=metricas, n_jobs=-1, cv=5, return_train_score=True, refit = 'roc_auc'\n",
    ").fit(X_train_reducido, y_train)\n",
    "\n",
    "informe.imprimir_metricas(rscv, X_train_reducido, y_train, nombre = \"modelo 2\")\n",
    "\n",
    "modelo2 = rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3acf997",
   "metadata": {},
   "source": [
    "#### Modelo 3\n",
    "- Con los feautures mas relevantes se arma un ensamble usando la estrategia bagging con la cual se construyen multiples estimadores para definir las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd746f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados modelo 3\n",
      "    Mejores hiperparámetros: {'base_estimator__min_samples_leaf': 2, 'base_estimator__max_depth': 8}\n",
      "    Métrica AUC ROC: 0.91\n",
      "    Otras metricas:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     17303\n",
      "           1       0.81      0.55      0.66      5489\n",
      "\n",
      "    accuracy                           0.86     22792\n",
      "   macro avg       0.84      0.75      0.78     22792\n",
      "weighted avg       0.86      0.86      0.85     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo3 = BaggingClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "params = {'base_estimator__max_depth': np.arange(2, 9), 'base_estimator__min_samples_leaf': np.arange(2, 16)}\n",
    "metricas = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    modelo3, params, n_iter=60, scoring=metricas, n_jobs=-1, cv=5, return_train_score=True, refit = 'roc_auc'\n",
    ").fit(X_train_reducido, y_train)\n",
    "\n",
    "informe.imprimir_metricas(rscv, X_train_reducido, y_train, nombre = \"modelo 3\")\n",
    "\n",
    "modelo3 = rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e55322f",
   "metadata": {},
   "source": [
    "#### Modelo 4\n",
    "- Análogo al modelo 3, pero usando un ensamble de tipo random forest, el cual es más adecuada para ensamble de arboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cdf9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo4 = RandomForestClassifier(max_depth=20)\n",
    "\n",
    "params = {'max_depth': np.arange(2, 9), 'min_samples_leaf': np.arange(2, 16)}\n",
    "metricas = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    modelo4, params, n_iter=60, scoring=metricas, n_jobs=-1, cv=5, return_train_score=True, refit = 'roc_auc'\n",
    ").fit(X_train_reducido, y_train)\n",
    "\n",
    "informe.imprimir_metricas(rscv, X_train_reducido, y_train, nombre = \"modelo 4\")\n",
    "\n",
    "modelo4 = rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d40f3b",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "      En base a la metrica AUC-ROC, se ve que los 4 modelos performan practicamente igual. Sin mayor justificación se elige el modelo 4, ya que en general los ensamblados brindan buenos resultados y el random forest esta pensado justamente para arboles.\n",
    "      \n",
    "### Informe del modelo 2 usando los datos del test_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69df9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "informe.imprimir_informe(modelo4, X_holdout_reducido, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a9da9",
   "metadata": {},
   "source": [
    "### Conclusiones de las métricas observadas de los datos de hold_out\n",
    "\n",
    "- accuracy:\n",
    "\n",
    "        El modelo clasifica los datos de forma correcta en aproximadamente un 85%, viendo la distribucion de clases de la muestra se observa que el 0 es la clase mayoritaria con una proporción de aproximadamente 76%. Por lo tanto el modelo es mejor predictor que devolver siempre cero.\n",
    "    \n",
    "    \n",
    "- precisión:\n",
    "\n",
    "        La fracción de predicciones de 0's que realmente eran 0's fue de aproximadamente 87% y la fracción de predicciones de 1's que realmente eran 1's fue del 79% \n",
    "\n",
    "\n",
    "- recall:\n",
    "\n",
    "        Los 0's reales detectados fueron aproximadamente del 96%, y los 1's reales detectados fueron del 53%. Viendo este resultado en conjunto con la precisión, se entiende que el modelo es bueno prediciendo los 0's pero prediciendo los 1's tiene un comportamiento aleatorio, ya que aproximadamente la mitad de las veces lo detecta y la otra mitad no \n",
    "\n",
    "\n",
    "- f1 score:\n",
    "   \n",
    "       La calidad del modelo es de 84% en terminos del recall y la precision asi como el balance entre ambas.\n",
    "       \n",
    "       \n",
    "- matriz de confusion:\n",
    "\n",
    "        Se puede ver que las predicciones mayoritarias caen en la diagonal principal, lo cual es una buena caracteristica de una matriz de confusión. Sin embargo para los 1's, las dos columnas estan demasiado balanceadas, lo cual ya se sabia ya que en el resultado de recall para los 1's era aproximadamente del 50%.\n",
    "        Aproximadamente el 85% de las instancias se encuentran en la diagonal principal, (lo cual ya sabiamos por el accuracy del 85%)\n",
    "        \n",
    "        \n",
    "- UAC ROC:\n",
    "\n",
    "        Esta métrica indica que el modelo es bueno distinguiendo clases en un 91%. Este valor será utilizado para decidir sobre la elección de este modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270e8a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
